{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "H2ATwb0MMHPw",
    "outputId": "8e50a451-e759-4232-8cbe-e74fb9acd627"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WMmXCpsICqEO",
    "outputId": "9783ef98-ca25-4956-db41-3af4b8354162"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 1.x selected.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "colab_type": "code",
    "id": "iJykedPGCzxo",
    "outputId": "1e27276e-a17b-4ed5-eccd-08ff340ef93a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.2\n",
      "Fri Jun 19 03:08:49 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   37C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                 ERR! |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AYIQVaC-L-WS",
    "outputId": "600ac5c1-67ec-4165-e89a-a9f4ec1260c9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "from torch.utils.data import Dataset, Subset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l4qRrZpHMTgG"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/drive/My Drive/Master_Final_Project/Genetic_attack/Code/nlp_adversarial_example_master_pytorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yeHn1qqnL-Wb"
   },
   "outputs": [],
   "source": [
    "import data_utils\n",
    "import glove_utils\n",
    "import models\n",
    "import display_utils\n",
    "from goog_lm import LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fsTKr4WAL-Wg"
   },
   "outputs": [],
   "source": [
    "import lm_data_utils\n",
    "import lm_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bTRAdZefcwn4"
   },
   "outputs": [],
   "source": [
    "#IMDB DATA downloading\n",
    "%%shell \n",
    "wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "tar -xvzf aclImdb_v1.tar.gz\n",
    "rm -f  aclImdb_v1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sMau53MQQvxk"
   },
   "outputs": [],
   "source": [
    "#SNLI dataset download\n",
    "%%shell\n",
    "wget -O snli_data.zip https://nlp.stanford.edu/projects/snli/snli_1.0.zip \n",
    "unzip snli_data -d snli_data\n",
    "rm -rf snli_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RKUlVaJEQ5N8"
   },
   "outputs": [],
   "source": [
    "#counter-fitted vectors download\n",
    "%%shell\n",
    "wget https://raw.githubusercontent.com/nmrksic/counter-fitting/master/word_vectors/counter-fitted-vectors.txt.zip\n",
    "unzip counter-fitted-vectors.txt.zip\n",
    "rm counter-fitted-vectors.txt.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "39EYTKjLlOGI"
   },
   "outputs": [],
   "source": [
    "%%shell\n",
    "test -d goog_lm || mkdir goog_lm\n",
    "cd goog_lm\n",
    "# Actually download the model files.\n",
    "# links are from: https://github.com/tensorflow/models/tree/master/research/lm_1b\n",
    "wget http://download.tensorflow.org/models/LM_LSTM_CNN/graph-2016-09-10.pbtxt\n",
    "wget http://download.tensorflow.org/models/LM_LSTM_CNN/all_shards-2016-09-10/ckpt-base\n",
    "wget http://download.tensorflow.org/models/LM_LSTM_CNN/all_shards-2016-09-10/ckpt-char-embedding\n",
    "wget http://download.tensorflow.org/models/LM_LSTM_CNN/all_shards-2016-09-10/ckpt-lstm\n",
    "wget http://download.tensorflow.org/models/LM_LSTM_CNN/all_shards-2016-09-10/ckpt-softmax0\n",
    "wget http://download.tensorflow.org/models/LM_LSTM_CNN/all_shards-2016-09-10/ckpt-softmax1\n",
    "wget http://download.tensorflow.org/models/LM_LSTM_CNN/all_shards-2016-09-10/ckpt-softmax2\n",
    "wget http://download.tensorflow.org/models/LM_LSTM_CNN/all_shards-2016-09-10/ckpt-softmax3\n",
    "wget http://download.tensorflow.org/models/LM_LSTM_CNN/all_shards-2016-09-10/ckpt-softmax4\n",
    "wget http://download.tensorflow.org/models/LM_LSTM_CNN/all_shards-2016-09-10/ckpt-softmax5\n",
    "wget http://download.tensorflow.org/models/LM_LSTM_CNN/all_shards-2016-09-10/ckpt-softmax6\n",
    "wget http://download.tensorflow.org/models/LM_LSTM_CNN/all_shards-2016-09-10/ckpt-softmax7\n",
    "wget http://download.tensorflow.org/models/LM_LSTM_CNN/all_shards-2016-09-10/ckpt-softmax8\n",
    "wget http://download.tensorflow.org/models/LM_LSTM_CNN/vocab-2016-09-10.txt\n",
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "colab_type": "code",
    "id": "oRGpWkb_OgA0",
    "outputId": "30647541-c135-410a-d101-f2bc0387012a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizing...\n",
      "Dataset built !\n",
      "Loading Glove Model\n",
      "Done. 2196007  words loaded!\n",
      "Number of not found words =  7982\n",
      "Loading Glove Model\n",
      "Done. 65713  words loaded!\n",
      "Number of not found words =  15153\n",
      "All done\n"
     ]
    }
   ],
   "source": [
    "import build_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WFkMyjrML-Wj",
    "outputId": "c65a7779-1bc0-4704-8000-8e2c6139e597"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f1dce7528b0>"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1001)\n",
    "torch.manual_seed(1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YAO-QhtuL-Wn"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vwwhd5aXL-Wr"
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE  = 50000\n",
    "with open('aux_files/dataset_%d.pkl' %VOCAB_SIZE, 'rb') as f:\n",
    "    dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cZr0ZVkpL-Wy"
   },
   "outputs": [],
   "source": [
    "doc_len = [len(dataset.test_seqs2[i]) for i in \n",
    "           range(len(dataset.test_seqs2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A3lSUbr9L-W2"
   },
   "outputs": [],
   "source": [
    "skip_list = np.load('aux_files/missed_embeddings_counter_%d.npy' %VOCAB_SIZE)\n",
    "# [300, 50001] 'UKN':50000; The first has no meaning\n",
    "MAX_VOCAB_SIZE = 50000\n",
    "embedding_matrix = np.load('aux_files/embeddings_glove_%d.npy' %(MAX_VOCAB_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yolIlp1NF47S"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from compute_dist import compute_dis\n",
    "from SA_model import SentimentAnalysis\n",
    "from data_cluster_seg import Data_infor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f-E6IyzcL-W6"
   },
   "source": [
    "### Demonstrating how we find the most similar words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 837
    },
    "colab_type": "code",
    "id": "cYyoJi94S6ni",
    "outputId": "feea47bb-7b27-4802-a8e0-4e8eb42ce359"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest to `later` are:\n",
      " --  subsequent   0.18323109771400037\n",
      " --  subsequently   0.1867195991340005\n",
      " --  afterward   0.2509214012219998\n",
      " --  afterwards   0.2576958961479996\n",
      " --  thereafter   0.27419810965900027\n",
      " --  trailing   0.33680027128100054\n",
      " --  after   0.34520261237799943\n",
      " --  then   0.36472839338299945\n",
      " --  posterior   0.4310855888390004\n",
      " --  following   0.48330736760400006\n",
      "Closest to `takes` are:\n",
      " --  pick   0.311305465632\n",
      " --  taking   0.4247115846279994\n",
      " --  picked   0.4852741249590007\n",
      "Closest to `instead` are:\n",
      " --  conversely   0.3034038049850005\n",
      " --  however   0.34753828658300034\n",
      " --  alternatively   0.39540487543000014\n",
      " --  alternately   0.4439627395600001\n",
      " --  nevertheless   0.4771639757920001\n",
      "Closest to `seem` are:\n",
      " --  seems   0.007052995653001437\n",
      " --  appears   0.328372447352\n",
      " --  looks   0.3353463830640009\n",
      " --  transpires   0.456207185493001\n",
      "Closest to `beautiful` are:\n",
      " --  gorgeous   0.019236443661999614\n",
      " --  wonderful   0.10149643378300022\n",
      " --  splendid   0.10299021060600011\n",
      " --  handsome   0.11803810151499916\n",
      " --  resplendent   0.11808701124699961\n",
      " --  wondrous   0.12150066282499972\n",
      " --  marvelous   0.1251997553909987\n",
      " --  marvellous   0.12839834231899983\n",
      " --  fantastic   0.13626627125499935\n",
      " --  sumptuous   0.14140581277099984\n",
      " --  magnificent   0.14636687160099981\n",
      " --  terrific   0.15607668417800058\n",
      " --  lovely   0.16000762712299976\n",
      " --  ravishing   0.17404625231199944\n",
      " --  sublime   0.17909557696099898\n",
      " --  exquisite   0.18810714172800047\n",
      " --  fabulous   0.20363493095599927\n",
      " --  delightful   0.20468405530899858\n",
      " --  superb   0.21660537683000003\n",
      " --  excellent   0.22435712285300058\n"
     ]
    }
   ],
   "source": [
    "# Pytorch\n",
    "for i in range(300, 305):\n",
    "  nearest, nearest_dist = glove_utils.pick_most_similar_words(compute_dis(i), 20, 0.5)\n",
    "  print('Closest to `%s` are:' %(dataset.inv_dict[i]))\n",
    "  for w_id, w_dist in zip(nearest, nearest_dist):\n",
    "        print(' -- ', dataset.inv_dict[w_id], ' ', w_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cERTBm_DL-XF"
   },
   "source": [
    "## Loading the Google Language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "colab_type": "code",
    "id": "uqOFZhieL-XG",
    "outputId": "f4651fbe-a101-4afc-caf6-b4e95b55dc21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /content/drive/My Drive/Master_Final_Project/Genetic_attack/Code/nlp_adversarial_example_master_pytorch/lm_data_utils.py:40: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "LM vocab loading done\n",
      "WARNING:tensorflow:From /content/drive/My Drive/Master_Final_Project/Genetic_attack/Code/nlp_adversarial_example_master_pytorch/goog_lm.py:30: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/drive/My Drive/Master_Final_Project/Genetic_attack/Code/nlp_adversarial_example_master_pytorch/lm_utils.py:21: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n",
      "WARNING:tensorflow:From /content/drive/My Drive/Master_Final_Project/Genetic_attack/Code/nlp_adversarial_example_master_pytorch/lm_utils.py:23: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /content/drive/My Drive/Master_Final_Project/Genetic_attack/Code/nlp_adversarial_example_master_pytorch/lm_utils.py:26: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "INFO:tensorflow:Recovering Graph goog_lm/graph-2016-09-10.pbtxt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering checkpoint goog_lm/ckpt-*\n"
     ]
    }
   ],
   "source": [
    "goog_lm = LM()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-qMfF9tlL-W-"
   },
   "source": [
    "### Preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7LQtx-aoL-W_"
   },
   "outputs": [],
   "source": [
    "max_len = 250\n",
    "train_x = pad_sequences(dataset.train_seqs2, maxlen=max_len, padding='post')\n",
    "train_y = np.array(dataset.train_y)\n",
    "test_x = pad_sequences(dataset.test_seqs2, maxlen=max_len, padding='post')\n",
    "test_y = np.array(dataset.test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5tRA2s-aLywC"
   },
   "outputs": [],
   "source": [
    "# pytorch\n",
    "\n",
    "max_len = 250\n",
    "padded_train_raw = pad_sequences(dataset.train_seqs2, maxlen = max_len, padding = 'post')\n",
    "padded_test_raw = pad_sequences(dataset.test_seqs2, maxlen = max_len, padding = 'post')\n",
    "# TrainSet\n",
    "data_set = Data_infor(padded_train_raw, dataset.train_y)\n",
    "num_train = len(data_set)\n",
    "indx = list(range(num_train))\n",
    "train_set = Subset(data_set, indx)\n",
    "\n",
    "# TestSet\n",
    "SAMPLE_SIZE = 5000\n",
    "data_set = Data_infor(padded_test_raw, dataset.test_y)\n",
    "num_test = len(data_set)\n",
    "indx = list(range(num_test))\n",
    "# indx = random.sample(indx, SAMPLE_SIZE)\n",
    "test_set = Subset(data_set, indx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3aCdEb7PM3Rp"
   },
   "outputs": [],
   "source": [
    "save_path = '/content/drive/My Drive/Master_Final_Project/Genetic_attack/Code/nlp_adversarial_example_master_pytorch'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3EfyaiqLL-XB"
   },
   "source": [
    "### Loading the sentiment analysis model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T-ohdFW6XOkE"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "embedding_matrix = torch.tensor(embedding_matrix.T).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "3nz8NGSrL-XC",
    "outputId": "8a22eb0c-9154-40cd-d131-75e68eeeadf2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentAnalysis(\n",
       "  (embed): Embedding(50001, 300)\n",
       "  (lstm): LSTM(300, 128, num_layers=2)\n",
       "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       "  (dropout): Dropout(p=0.09999999999999998, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_state_save = os.path.join(save_path,'best_SA')\n",
    "batch_size = 1\n",
    "lstm_size = 128\n",
    "\n",
    "model = SentimentAnalysis(batch_size=batch_size, embedding_matrix = embedding_matrix, hidden_size = lstm_size, kept_prob = 0.9)\n",
    "model.eval()\n",
    "model.load_state_dict(torch.load(rnn_state_save))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FzNabZP2c2Qi",
    "outputId": "2a14d61c-36c8-4d50-db7d-c795871ec24f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:0.9011.\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(test_set,batch_size = int(num_test/10), shuffle = False, pin_memory=True)\n",
    "model.eval()\n",
    "test_pred = torch.tensor([])\n",
    "test_targets = torch.tensor([])\n",
    "test_loss = []\n",
    "\n",
    "with torch.no_grad():\n",
    "  for batch_index, (seqs, length, target) in enumerate(test_loader):\n",
    "    seqs, target, length = seqs.to(device), target.to(device), length.to(device)\n",
    "    seqs = seqs.type(torch.LongTensor)\n",
    "    len_order = torch.argsort(length, descending = True)\n",
    "    length = length[len_order]\n",
    "    seqs = seqs[len_order]\n",
    "    target = target[len_order]\n",
    "\n",
    "    output = model.pred(seqs, length)\n",
    "    test_pred = torch.cat((test_pred, output.cpu()), dim = 0)\n",
    "    test_targets = torch.cat((test_targets, target.type(torch.float).cpu()))\n",
    "\n",
    "  accuracy = model.evaluate_accuracy(test_pred.numpy(), test_targets.numpy())\n",
    "  print('Test Accuracy:{:.4f}.'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iVnXZcrU0_hr"
   },
   "outputs": [],
   "source": [
    "# TestSet\n",
    "SAMPLE_SIZE = 5000\n",
    "data_set = Data_infor(padded_test_raw, dataset.test_y)\n",
    "num_test = len(data_set)\n",
    "indx = list(range(num_test))\n",
    "indx = random.sample(indx, SAMPLE_SIZE)\n",
    "test_set = Subset(data_set, indx)\n",
    "test_loader = DataLoader(test_set,batch_size = 1, shuffle = False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VZJJkC49Mm8v"
   },
   "outputs": [],
   "source": [
    "torch.save(test_loader, os.path.join(save_path, 'test_loader'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "03vQVcBcNYOh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "cEdwMyz3L-XJ"
   },
   "source": [
    "#### demonstrating the GoogLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "GUcaHeEAL-XK",
    "outputId": "2f0bb5ef-d1b3-44f3-c198-981a99b84aee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest to `play` are ['playing', 'gaming', 'games', 'toy', 'playback', 'game', 'plaything', 'cheek', 'gambling', 'toys', 'toying', 'replay', 'stake', 'plays', 'jeu', 'gamble', 'staking', 'reproduction', 'casino', 'sets']\n"
     ]
    }
   ],
   "source": [
    "src_word = dataset.dict['play']\n",
    "nearest, nearest_dist = glove_utils.pick_most_similar_words(compute_dis(src_word),20)\n",
    "nearest_w = [dataset.inv_dict[x] for x in nearest]\n",
    "print('Closest to `%s` are %s' %(dataset.inv_dict[src_word], nearest_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KzOKu55lL-XO",
    "outputId": "454d7ce9-adac-4ba5-9ebb-19df4721f1a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most probable is  game\n"
     ]
    }
   ],
   "source": [
    "prefix = 'is'\n",
    "suffix = 'with'\n",
    "lm_preds = goog_lm.get_words_probs(prefix, nearest_w, suffix)\n",
    "print('most probable is ', nearest_w[np.argmax(lm_preds)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TBdOzDoNL-XR"
   },
   "source": [
    "## Try Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cd3I7A42L-XS"
   },
   "outputs": [],
   "source": [
    "from attacks import GeneticAtack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nRlygVDgL-XV"
   },
   "source": [
    "## Main Attack "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YlyBJmfPL-XW"
   },
   "outputs": [],
   "source": [
    "n1 = 8\n",
    "n2 = 4\n",
    "pop_size = 60\n",
    "max_iters = 30\n",
    "\n",
    "batch_model = SentimentAnalysis(batch_size=pop_size, embedding_matrix = embedding_matrix, hidden_size = lstm_size, kept_prob = None)\n",
    "\n",
    "batch_model.eval()\n",
    "batch_model.load_state_dict(torch.load(rnn_state_save))\n",
    "batch_model.to(device)\n",
    "\n",
    "neighbour_model = SentimentAnalysis(batch_size=batch_size, embedding_matrix = embedding_matrix, hidden_size = lstm_size, kept_prob = None)\n",
    "\n",
    "neighbour_model.eval()\n",
    "neighbour_model.load_state_dict(torch.load(rnn_state_save))\n",
    "neighbour_model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X1RoWvo7JHPb"
   },
   "outputs": [],
   "source": [
    "\n",
    "class GeneticAttack_pytorch(object):\n",
    "  def __init__(self, model, batch_model, neighbour_model, compute_dis,\n",
    "               goog_lm, max_iters, dataset,\n",
    "               pop_size, n1, n2,\n",
    "               use_lm = True, use_suffix = False):\n",
    "    self.model = model\n",
    "    self.batch_model = batch_model\n",
    "    self.neighbour_model = neighbour_model\n",
    "    self.model.eval()\n",
    "    self.batch_model.eval()\n",
    "    self.neighbour_model.eval()\n",
    "    self.compute_dist = compute_dis\n",
    "    self.pop_size = pop_size\n",
    "    self.top_n1 = n1\n",
    "    self.top_n2 = n2\n",
    "    self.use_lm = use_lm\n",
    "    self.use_suffix = use_suffix\n",
    "    self.w_i_dict = dataset.dict\n",
    "    self.i_w_dict = dataset.inv_dict\n",
    "    self.dataset = dataset\n",
    "    self.lm = goog_lm\n",
    "    self.temp = 0.3\n",
    "    self.max_iters = max_iters\n",
    "    \n",
    "\n",
    "  def attack(self, seq, target, l, max_change = 0.4):\n",
    "    seq = seq.numpy().squeeze()\n",
    "    seq_adv = seq.copy()\n",
    "    seq_len = np.sum(np.sign(seq))\n",
    "    l = l.cpu()\n",
    "    # To calculate the sampling probability \n",
    "    tmp = [glove_utils.pick_most_similar_words(self.compute_dist(i), ret_count = 50, threshold = 0.5) for i in seq]\n",
    "    neighbour_list = [t[0] for t in tmp]\n",
    "    neighbour_dist = [t[1] for t in tmp]\n",
    "    neighbour_len = [len(i) for i in neighbour_list]\n",
    "    for i in range(seq_len):\n",
    "      if seq[i] < 27:\n",
    "        neighbour_len[i] = 0\n",
    "    prob_select = neighbour_len/np.sum(neighbour_len)\n",
    "    tmp = [glove_utils.pick_most_similar_words(\n",
    "        self.compute_dist(i), self.top_n1, 0.5\n",
    "    ) for i in seq]\n",
    "    neighbour_list = [t[0] for t in tmp]\n",
    "    neighbour_dist = [t[1] for t in tmp]\n",
    "    pop = [self.perturb(seq_adv, seq, neighbour_list, neighbour_dist, prob_select, seq_len, target, l) for _ in range(self.pop_size)]\n",
    "\n",
    "    l_tensor = l*torch.ones([len(pop)])\n",
    "    pop_np = np.expand_dims(pop[0], 0)\n",
    "    for p in pop[1:]:\n",
    "      pop_np = np.concatenate((pop_np, np.expand_dims(p, 0)),0) \n",
    "\n",
    "    for i in range(self.max_iters):\n",
    "      pop_tensor = torch.tensor(pop_np).type(torch.LongTensor).to(device)\n",
    "      l_tensor = l_tensor.to(device)\n",
    "      self.batch_model.eval()\n",
    "      with torch.no_grad():\n",
    "        pop_preds = self.batch_model.pred(pop_tensor, l_tensor).cpu().detach().numpy()\n",
    "      \n",
    "      pop_scores = pop_preds[:, target]\n",
    "      print('\\t\\t', i, ' -- ', np.max(pop_scores))\n",
    "      pop_ranks = np.argsort(pop_scores)[::-1]\n",
    "      top_attack = pop_ranks[0]\n",
    "\n",
    "      logits = np.exp(pop_scores/self.temp)\n",
    "      select_probs = logits/np.sum(logits)\n",
    "    \n",
    "      if np.argmax(pop_preds[top_attack, :]) == target:\n",
    "        print('Success and score: {:.4f}'.format(pop_scores[top_attack]))\n",
    "        return pop[top_attack]\n",
    "      \n",
    "      elite = [pop[top_attack]]  # elite\n",
    "      # print(select_probs.shape)\n",
    "      parent1_idx = np.random.choice(\n",
    "          self.pop_size, size=self.pop_size-1, p=select_probs)\n",
    "      parent2_idx = np.random.choice(\n",
    "          self.pop_size, size=self.pop_size-1, p=select_probs)\n",
    "      \n",
    "      childs = [self.crossover(pop[parent1_idx[i]],\n",
    "                                pop[parent2_idx[i]])\n",
    "                for i in range(self.pop_size-1)]\n",
    "      childs = [self.perturb(\n",
    "          x, seq, neighbour_list, neighbour_dist, prob_select, seq_len, target, l) for x in childs]\n",
    "      pop = elite + childs\n",
    "      pop_np = np.expand_dims(pop[0], 0)\n",
    "      for p in pop[1:]:\n",
    "        pop_np = np.concatenate((pop_np, np.expand_dims(p, 0)),0)\n",
    "\n",
    "    return None\n",
    "    \n",
    "  def perturb(self, seq_cur, seq, neighbour_list, neighbour_dist, prob_select, seq_len, target, l):\n",
    "    prob_len = len(prob_select)\n",
    "    rand_idx = np.random.choice(prob_len, 1, p = prob_select)[0]\n",
    "    while seq_cur[rand_idx] != seq[rand_idx] and np.sum(seq != seq_cur)<np.sum(np.sign(prob_select)):\n",
    "      rand_idx = np.random.choice(prob_len, 1, p = prob_select)[0]\n",
    "    \n",
    "    replace_list = neighbour_list[rand_idx]\n",
    "    if len(replace_list) < self.top_n1:\n",
    "      replace_list = np.concatenate((replace_list, np.zeros(self.top_n1 - replace_list.shape[0])))\n",
    "    return self.select_best_replacement(rand_idx, seq_cur, seq, target, l, replace_list)\n",
    "  \n",
    "  def replace(self, seq_cur, loc, w):\n",
    "    seq_new = seq_cur.copy()\n",
    "    seq_new[loc] = w\n",
    "    return seq_new\n",
    "\n",
    "\n",
    "  def select_best_replacement(self, loc, seq_cur, seq, target, l, replace_list):\n",
    "    new_seq_list = [self.replace(seq_cur, loc, w) if seq[loc]!=w and w != 0 else seq_cur for w in replace_list]\n",
    "    l_seq_list = len(new_seq_list)\n",
    "    new_seq_list_tensor = torch.tensor(new_seq_list).type(torch.LongTensor).to(device)\n",
    "    l_tensor = l*torch.ones([l_seq_list])\n",
    "    l_tensor = l_tensor.to(device)\n",
    "    self.neighbour_model.eval()\n",
    "    with torch.no_grad():\n",
    "      new_seq_preds = self.neighbour_model.pred(new_seq_list_tensor, l_tensor).cpu().detach().numpy()\n",
    "    new_seq_scores = new_seq_preds[:, target]\n",
    "    seq_tensor = torch.tensor(np.expand_dims(seq, axis = 0)).type(torch.LongTensor).to(device)\n",
    "    l_tensor = l.to(device)\n",
    "    self.model.eval()\n",
    "    with torch.no_grad():\n",
    "      orig_score = self.model.pred(seq_tensor, l_tensor).cpu().detach().numpy()[0, target]\n",
    "    new_seq_scores -= orig_score\n",
    "    \n",
    "    new_seq_scores[self.top_n1:] = -10000000\n",
    "    \n",
    "    if self.use_lm:\n",
    "      prefix = ''\n",
    "      suffix = None\n",
    "      if loc > 0:\n",
    "        prefix = self.i_w_dict[seq_cur[loc-1]]\n",
    "\n",
    "\n",
    "      orig_word = self.i_w_dict[seq[loc]]\n",
    "      if self.use_suffix and loc < seq_cur.shape[0]-1 and seq_cur[pos+1]!=0:\n",
    "        suffix = self.i_w_dict[seq_cur[pos+1]]\n",
    "      replace_words_orig = [self.dataset.inv_dict[w] if w in self.dataset.inv_dict else 'UNK' for w in replace_list[:self.top_n1]] + [orig_word]\n",
    "\n",
    "      replace_words_scores = self.lm.get_words_probs(prefix, replace_words_orig, suffix)\n",
    "        \n",
    "      new_words_scores = np.array(replace_words_scores[:-1])\n",
    "      rank_replaces_by_lm = np.argsort(-new_words_scores)\n",
    "      filtered_words_idx = rank_replaces_by_lm[self.top_n2:]\n",
    "\n",
    "      new_seq_scores[filtered_words_idx] = -10000000\n",
    "\n",
    "    if np.max(new_seq_scores)>0:    \n",
    "      return new_seq_list[np.argsort(new_seq_scores)[-1]]\n",
    "    return seq_cur\n",
    "\n",
    "  def crossover(self, seq1, seq2):\n",
    "    seq_new = seq1.copy()\n",
    "    for i in range(len(seq1)):\n",
    "        if np.random.uniform() < 0.5:\n",
    "            seq_new[i] = seq2[i]\n",
    "    return seq_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_cF-fD1iKTm4"
   },
   "outputs": [],
   "source": [
    "ga_attack = GeneticAttack_pytorch(model, batch_model, neighbour_model, compute_dis,\n",
    "               goog_lm, max_iters = max_iters, dataset = dataset,\n",
    "               pop_size = pop_size, n1 = n1, n2 = n2,\n",
    "               use_lm = True, use_suffix = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "8aG4aQ_2MirN",
    "outputId": "a76b26a6-9bee-41e9-b61c-8deaaf77b203"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence number:0\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:1\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:2\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:3\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:4\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:5\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:6\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:7\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:8\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:9\n",
      "Length of sentence: 62, Number of samples:1\n",
      "\t\t 0  --  1.2732394e-25\n",
      "\t\t 1  --  2.358753e-19\n",
      "\t\t 2  --  4.347459e-18\n",
      "\t\t 3  --  2.0122895e-13\n",
      "\t\t 4  --  2.7647e-10\n",
      "\t\t 5  --  7.271452e-10\n",
      "\t\t 6  --  4.1930864e-08\n",
      "\t\t 7  --  0.000110052315\n",
      "\t\t 8  --  0.0016444275\n",
      "\t\t 9  --  0.9882933\n",
      "Success and score: 0.9883\n",
      "trio ----> triangular\n",
      "related ----> connected\n",
      "themes ----> items\n",
      "all ----> everyone\n",
      "quite ----> rather\n",
      "executed ----> conducted\n",
      "widely ----> largely\n",
      "distributed ----> circulated\n",
      "however ----> instead\n",
      "had ----> ha\n",
      "none ----> no\n",
      "local ----> locale\n",
      "even ----> also\n",
      "----------------------\n",
      "Sequence number:10\n",
      "Wrong original prediction\n",
      "----------------------\n",
      "Sequence number:11\n",
      "Wrong original prediction\n",
      "----------------------\n",
      "Sequence number:12\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:13\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:14\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:15\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:16\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:17\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:18\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:19\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:20\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:21\n",
      "Wrong original prediction\n",
      "----------------------\n",
      "Sequence number:22\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:23\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:24\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:25\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:26\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:27\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:28\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:29\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:30\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:31\n",
      "Wrong original prediction\n",
      "----------------------\n",
      "Sequence number:32\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:33\n",
      "Length of sentence: 64, Number of samples:2\n",
      "\t\t 0  --  0.52195483\n",
      "Success and score: 0.5220\n",
      "showed ----> indicated\n",
      "----------------------\n",
      "Sequence number:34\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:35\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:36\n",
      "Length of sentence: 55, Number of samples:3\n",
      "\t\t 0  --  1.4662916e-37\n",
      "\t\t 1  --  6.1858886e-20\n",
      "\t\t 2  --  7.14683e-19\n",
      "\t\t 3  --  9.461851e-16\n",
      "\t\t 4  --  3.5092565e-10\n",
      "\t\t 5  --  3.5092565e-10\n",
      "\t\t 6  --  1.2383784e-06\n",
      "\t\t 7  --  1.2383784e-06\n",
      "\t\t 8  --  0.030628232\n",
      "\t\t 9  --  0.97795725\n",
      "Success and score: 0.9780\n",
      "great ----> grand\n",
      "tech ----> technician\n",
      "technology ----> tech\n",
      "boggling ----> boggles\n",
      "packed ----> packaging\n",
      "guys ----> guy\n",
      "will ----> volition\n",
      "want ----> wanted\n",
      "very ----> much\n",
      "very ----> much\n",
      "very ----> much\n",
      "unique ----> peculiar\n",
      "plot ----> conspiracies\n",
      "----------------------\n",
      "Sequence number:37\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:38\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:39\n",
      "Length of sentence: 48, Number of samples:4\n",
      "\t\t 0  --  0.00092924904\n",
      "\t\t 1  --  0.34925506\n",
      "\t\t 2  --  0.87985355\n",
      "Success and score: 0.8799\n",
      "very ----> extremely\n",
      "favourite ----> preferred\n",
      "whole ----> total\n",
      "times ----> period\n",
      "----------------------\n",
      "Sequence number:40\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:41\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:42\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:43\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:44\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:45\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:46\n",
      "Wrong original prediction\n",
      "----------------------\n",
      "Sequence number:47\n",
      "Wrong original prediction\n",
      "----------------------\n",
      "Sequence number:48\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:49\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:50\n",
      "Wrong original prediction\n",
      "----------------------\n",
      "Sequence number:51\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:52\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:53\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:54\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:55\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:56\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:57\n",
      "Length of sentence: 34, Number of samples:5\n",
      "\t\t 0  --  8.617981e-22\n",
      "\t\t 1  --  7.504202e-18\n",
      "\t\t 2  --  1.0\n",
      "Success and score: 1.0000\n",
      "waits ----> awaiting\n",
      "worst ----> toughest\n",
      "----------------------\n",
      "Sequence number:58\n",
      "Wrong original prediction\n",
      "----------------------\n",
      "Sequence number:59\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:60\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:61\n",
      "Length of sentence: 61, Number of samples:6\n",
      "\t\t 0  --  8.040742e-09\n",
      "\t\t 1  --  1.3167456e-05\n",
      "\t\t 2  --  1.3167456e-05\n",
      "\t\t 3  --  0.17510353\n",
      "\t\t 4  --  0.7665074\n",
      "Success and score: 0.7665\n",
      "nothing ----> no\n",
      "much ----> highly\n",
      "joke ----> farce\n",
      "getting ----> gaining\n",
      "untill ----> havent\n",
      "endure ----> withstand\n",
      "----------------------\n",
      "Sequence number:62\n",
      "Wrong original prediction\n",
      "----------------------\n",
      "Sequence number:63\n",
      "Wrong original prediction\n",
      "----------------------\n",
      "Sequence number:64\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:65\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:66\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:67\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:68\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:69\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:70\n",
      "Length of sentence: 97, Number of samples:7\n",
      "\t\t 0  --  0.8250815\n",
      "Success and score: 0.8251\n",
      "correct ----> accurate\n",
      "----------------------\n",
      "Sequence number:71\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:72\n",
      "Length of sentence: 54, Number of samples:8\n",
      "\t\t 0  --  0.9614048\n",
      "Success and score: 0.9614\n",
      "better ----> nicer\n",
      "----------------------\n",
      "Sequence number:73\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:74\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:75\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:76\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:77\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:78\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:79\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:80\n",
      "Wrong original prediction\n",
      "----------------------\n",
      "Sequence number:81\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:82\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:83\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:84\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:85\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:86\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:87\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:88\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:89\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:90\n",
      "Wrong original prediction\n",
      "----------------------\n",
      "Sequence number:91\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:92\n",
      "Wrong original prediction\n",
      "----------------------\n",
      "Sequence number:93\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:94\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:95\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:96\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:97\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:98\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:99\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:100\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:101\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:102\n",
      "Length of sentence: 93, Number of samples:9\n",
      "\t\t 0  --  2.1909428e-23\n",
      "\t\t 1  --  2.9274516e-20\n",
      "\t\t 2  --  2.6729454e-15\n",
      "\t\t 3  --  3.531106e-09\n",
      "\t\t 4  --  8.380239e-06\n",
      "\t\t 5  --  8.380239e-06\n",
      "\t\t 6  --  8.380239e-06\n",
      "\t\t 7  --  8.380239e-06\n",
      "\t\t 8  --  7.178452e-05\n",
      "\t\t 9  --  0.9007257\n",
      "Success and score: 0.9007\n",
      "best ----> higher\n",
      "very ----> much\n",
      "funny ----> amusing\n",
      "made ----> conducted\n",
      "brilliant ----> marvellous\n",
      "performances ----> depictions\n",
      "movies ----> movie\n",
      "especially ----> specifically\n",
      "andreas ----> anders\n",
      "though ----> whilst\n",
      "absolutely ----> altogether\n",
      "proper ----> decent\n",
      "really ----> honestly\n",
      "buy ----> purchase\n",
      "----------------------\n",
      "Sequence number:103\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:104\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:105\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:106\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:107\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:108\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:109\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:110\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:111\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:112\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:113\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:114\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:115\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:116\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:117\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:118\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:119\n",
      "Wrong original prediction\n",
      "----------------------\n",
      "Sequence number:120\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:121\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:122\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:123\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:124\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:125\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:126\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:127\n",
      "Wrong original prediction\n",
      "----------------------\n",
      "Sequence number:128\n",
      "Length of sentence: 71, Number of samples:10\n",
      "\t\t 0  --  4.7762153e-22\n",
      "\t\t 1  --  6.111233e-20\n",
      "\t\t 2  --  1.2609241e-17\n",
      "\t\t 3  --  2.0201999e-17\n",
      "\t\t 4  --  8.738203e-17\n",
      "\t\t 5  --  7.770337e-12\n",
      "\t\t 6  --  1.0131569e-11\n",
      "\t\t 7  --  8.851829e-11\n",
      "\t\t 8  --  9.442802e-11\n",
      "\t\t 9  --  2.45817e-09\n",
      "\t\t 10  --  7.028717e-08\n",
      "\t\t 11  --  3.2524217e-06\n",
      "\t\t 12  --  3.2524217e-06\n",
      "\t\t 13  --  3.2524217e-06\n",
      "\t\t 14  --  5.3767188e-05\n",
      "\t\t 15  --  0.0010036568\n",
      "\t\t 16  --  0.0042820843\n",
      "\t\t 17  --  0.013678176\n",
      "\t\t 18  --  0.017754858\n",
      "\t\t 19  --  0.017754858\n",
      "\t\t 20  --  0.90912205\n",
      "Success and score: 0.9091\n",
      "tv ----> telly\n",
      "taping ----> tapes\n",
      "very ----> much\n",
      "intriguing ----> enigmatic\n",
      "amazing ----> staggering\n",
      "events ----> incident\n",
      "past ----> preceding\n",
      "catches ----> harvest\n",
      "story ----> stories\n",
      "exactly ----> downright\n",
      "claims ----> claiming\n",
      "fate ----> fates\n",
      "no ----> none\n",
      "could ----> ca\n",
      "life ----> living\n",
      "man ----> bloke\n",
      "had ----> ha\n",
      "at ----> under\n",
      "beginning ----> start\n",
      "----------------------\n",
      "Sequence number:129\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:130\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:131\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:132\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:133\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:134\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:135\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:136\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:137\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:138\n",
      "Length of sentence: 61, Number of samples:11\n",
      "\t\t 0  --  5.4050744e-18\n",
      "\t\t 1  --  0.00041502784\n",
      "\t\t 2  --  0.00041502784\n",
      "\t\t 3  --  0.0006841123\n",
      "\t\t 4  --  0.003600035\n",
      "\t\t 5  --  0.2169578\n",
      "\t\t 6  --  1.0\n",
      "Success and score: 1.0000\n",
      "most ----> biggest\n",
      "definitely ----> undoubtedly\n",
      "most ----> greatest\n",
      "terrible ----> horrifying\n",
      "bad ----> wicked\n",
      "at ----> in\n",
      "waste ----> debris\n",
      "----------------------\n",
      "Sequence number:139\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:140\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:141\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:142\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:143\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:144\n",
      "Length of sentence: 85, Number of samples:12\n",
      "\t\t 0  --  1.0500142e-18\n",
      "\t\t 1  --  2.909146e-15\n",
      "\t\t 2  --  2.394689e-14\n",
      "\t\t 3  --  5.1015626e-08\n",
      "\t\t 4  --  7.116611e-05\n",
      "\t\t 5  --  7.116611e-05\n",
      "\t\t 6  --  0.00042832352\n",
      "\t\t 7  --  0.0018621908\n",
      "\t\t 8  --  0.0018621908\n",
      "\t\t 9  --  0.09729475\n",
      "\t\t 10  --  0.99934775\n",
      "Success and score: 0.9993\n",
      "movies ----> cinema\n",
      "adapted ----> adapts\n",
      "fairly ----> somewhat\n",
      "conventionally ----> usually\n",
      "comic ----> hilarious\n",
      "style ----> elegance\n",
      "rising ----> increasing\n",
      "script ----> scenario\n",
      "wasted ----> missed\n",
      "time ----> times\n",
      "knee ----> lap\n",
      "jerk ----> dumbass\n",
      "brand ----> brands\n",
      "----------------------\n",
      "Sequence number:145\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:146\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:147\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:148\n",
      "Length of sentence: 64, Number of samples:13\n",
      "\t\t 0  --  0.3089875\n",
      "\t\t 1  --  0.6672255\n",
      "Success and score: 0.6672\n",
      "will ----> willpower\n",
      "again ----> even\n",
      "----------------------\n",
      "Sequence number:149\n",
      "Length of sentence: 65, Number of samples:14\n",
      "\t\t 0  --  9.939948e-08\n",
      "\t\t 1  --  2.3580906e-06\n",
      "\t\t 2  --  0.0020819975\n",
      "\t\t 3  --  0.1255446\n",
      "\t\t 4  --  0.99983513\n",
      "Success and score: 0.9998\n",
      "incredible ----> unbelievable\n",
      "horror ----> abomination\n",
      "complex ----> convoluted\n",
      "make ----> render\n",
      "if ----> unless\n",
      "----------------------\n",
      "Sequence number:150\n",
      "Length of sentence: 74, Number of samples:15\n",
      "\t\t 0  --  2.752418e-07\n",
      "\t\t 1  --  2.752418e-07\n",
      "\t\t 2  --  0.0019701987\n",
      "\t\t 3  --  0.02663203\n",
      "\t\t 4  --  0.1851097\n",
      "\t\t 5  --  0.99681735\n",
      "Success and score: 0.9968\n",
      "exceptionally ----> unusually\n",
      "well ----> bah\n",
      "all ----> whole\n",
      "around ----> about\n",
      "many ----> several\n",
      "teenagers ----> teen\n",
      "will ----> gonna\n",
      "excellent ----> magnificent\n",
      "----------------------\n",
      "Sequence number:151\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:152\n",
      "Wrong original prediction\n",
      "----------------------\n",
      "Sequence number:153\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:154\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:155\n",
      "Length of sentence: 80, Number of samples:16\n",
      "\t\t 0  --  0.9999975\n",
      "Success and score: 1.0000\n",
      "worst ----> toughest\n",
      "----------------------\n",
      "Sequence number:156\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:157\n",
      "Length of sentence: 75, Number of samples:17\n",
      "\t\t 0  --  4.0869574e-26\n",
      "\t\t 1  --  5.6580165e-24\n",
      "\t\t 2  --  5.6580165e-24\n",
      "\t\t 3  --  2.6340322e-14\n",
      "\t\t 4  --  2.6340322e-14\n",
      "\t\t 5  --  1.04078496e-13\n",
      "\t\t 6  --  2.5781047e-10\n",
      "\t\t 7  --  1.2869691e-07\n",
      "\t\t 8  --  1.2869691e-07\n",
      "\t\t 9  --  1.2869691e-07\n",
      "\t\t 10  --  1.8158473e-05\n",
      "\t\t 11  --  1.8158473e-05\n",
      "\t\t 12  --  1.8158473e-05\n",
      "\t\t 13  --  0.00024126522\n",
      "\t\t 14  --  0.1271896\n",
      "\t\t 15  --  0.76504695\n",
      "Success and score: 0.7650\n",
      "nothing ----> something\n",
      "juvenile ----> youthful\n",
      "come ----> arrives\n",
      "life ----> vie\n",
      "nothing ----> not\n",
      "more ----> larger\n",
      "excuse ----> apologise\n",
      "director ----> steering\n",
      "actor ----> player\n",
      "play ----> games\n",
      "woman ----> women\n",
      "otherwise ----> additionally\n",
      "give ----> giving\n",
      "simple ----> simpler\n",
      "nonexistent ----> absent\n",
      "while ----> although\n",
      "narrator ----> storyteller\n",
      "rating ----> ratings\n",
      "no ----> not\n",
      "----------------------\n",
      "Sequence number:158\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:159\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:160\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:161\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:162\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:163\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:164\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:165\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:166\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:167\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:168\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:169\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:170\n",
      "Length of sentence: 55, Number of samples:18\n",
      "\t\t 0  --  8.379688e-06\n",
      "\t\t 1  --  0.022570672\n",
      "\t\t 2  --  0.42359355\n",
      "\t\t 3  --  0.9999968\n",
      "Success and score: 1.0000\n",
      "best ----> finest\n",
      "cinema ----> film\n",
      "had ----> has\n",
      "worst ----> toughest\n",
      "more ----> most\n",
      "----------------------\n",
      "Sequence number:171\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:172\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:173\n",
      "Length of sentence: 67, Number of samples:19\n",
      "\t\t 0  --  0.10855814\n",
      "\t\t 1  --  0.23205172\n",
      "\t\t 2  --  0.9859051\n",
      "Success and score: 0.9859\n",
      "waiting ----> await\n",
      "waiting ----> waits\n",
      "happen ----> arise\n",
      "saving ----> rescued\n",
      "maybe ----> likely\n",
      "----------------------\n",
      "Sequence number:174\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:175\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:176\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:177\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:178\n",
      "Length of sentence: 74, Number of samples:20\n",
      "\t\t 0  --  0.8000124\n",
      "Success and score: 0.8000\n",
      "fine ----> fined\n",
      "----------------------\n",
      "Sequence number:179\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:180\n",
      "Wrong original prediction\n",
      "----------------------\n",
      "Sequence number:181\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:182\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:183\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:184\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:185\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:186\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:187\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:188\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:189\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:190\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:191\n",
      "Length of sentence: 60, Number of samples:21\n",
      "\t\t 0  --  1.8675818e-24\n",
      "\t\t 1  --  5.756665e-23\n",
      "\t\t 2  --  6.028672e-17\n",
      "\t\t 3  --  9.253024e-12\n",
      "\t\t 4  --  7.877614e-09\n",
      "\t\t 5  --  3.956958e-06\n",
      "\t\t 6  --  3.956958e-06\n",
      "\t\t 7  --  0.0007712384\n",
      "\t\t 8  --  0.0007712384\n",
      "\t\t 9  --  0.0019473899\n",
      "\t\t 10  --  0.10615811\n",
      "\t\t 11  --  0.9910789\n",
      "Success and score: 0.9911\n",
      "at ----> during\n",
      "how ----> why\n",
      "even ----> so\n",
      "throughout ----> around\n",
      "range ----> ranges\n",
      "wonderful ----> gorgeous\n",
      "over ----> finished\n",
      "where ----> everytime\n",
      "work ----> jobs\n",
      "most ----> longer\n",
      "excellent ----> magnificent\n",
      "combined ----> merged\n",
      "story ----> history\n",
      "like ----> fond\n",
      "waiting ----> hoping\n",
      "see ----> look\n",
      "very ----> much\n",
      "thoroughly ----> carefully\n",
      "enjoyed ----> cared\n",
      "flick ----> gesture\n",
      "----------------------\n",
      "Sequence number:192\n",
      "Length of sentence: 83, Number of samples:22\n",
      "\t\t 0  --  0.99991095\n",
      "Success and score: 0.9999\n",
      "ok ----> agree\n",
      "----------------------\n",
      "Sequence number:193\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:194\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:195\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:196\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:197\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:198\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:199\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:200\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:201\n",
      "Wrong original prediction\n",
      "----------------------\n",
      "Sequence number:202\n",
      "Length of sentence: 43, Number of samples:23\n",
      "\t\t 0  --  2.1720006e-10\n",
      "\t\t 1  --  1.0\n",
      "Success and score: 1.0000\n",
      "just ----> mere\n",
      "just ----> mere\n",
      "----------------------\n",
      "Sequence number:203\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:204\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:205\n",
      "Length of sentence: 66, Number of samples:24\n",
      "\t\t 0  --  1.8306264e-11\n",
      "\t\t 1  --  2.2154431e-06\n",
      "\t\t 2  --  0.0017302698\n",
      "\t\t 3  --  0.95896614\n",
      "Success and score: 0.9590\n",
      "loud ----> noisy\n",
      "formidable ----> whopping\n",
      "presence ----> attendance\n",
      "exploding ----> explosion\n",
      "enjoyable ----> nice\n",
      "----------------------\n",
      "Sequence number:206\n",
      "Length of sentence: 45, Number of samples:25\n",
      "\t\t 0  --  9.489012e-13\n",
      "\t\t 1  --  6.140357e-10\n",
      "\t\t 2  --  6.140357e-10\n",
      "\t\t 3  --  0.03015851\n",
      "\t\t 4  --  0.40450227\n",
      "\t\t 5  --  0.86806464\n",
      "Success and score: 0.8681\n",
      "worst ----> toughest\n",
      "started ----> begun\n",
      "things ----> issues\n",
      "idiotic ----> foolish\n",
      "absolutely ----> entirely\n",
      "definitely ----> doubtless\n",
      "if ----> although\n",
      "----------------------\n",
      "Sequence number:207\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:208\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:209\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:210\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:211\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:212\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:213\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:214\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:215\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:216\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:217\n",
      "Length of sentence: 45, Number of samples:26\n",
      "\t\t 0  --  7.026693e-12\n",
      "\t\t 1  --  1.3085164e-08\n",
      "\t\t 2  --  0.00017943827\n",
      "\t\t 3  --  0.00017943827\n",
      "\t\t 4  --  0.1302534\n",
      "\t\t 5  --  0.1302534\n",
      "\t\t 6  --  0.98571706\n",
      "Success and score: 0.9857\n",
      "if ----> although\n",
      "if ----> although\n",
      "several ----> many\n",
      "movies ----> films\n",
      "will ----> desire\n",
      "silly ----> foolish\n",
      "fully ----> altogether\n",
      "cliched ----> corny\n",
      "predictable ----> foreseeable\n",
      "waste ----> litter\n",
      "----------------------\n",
      "Sequence number:218\n",
      "Wrong original prediction\n",
      "----------------------\n",
      "Sequence number:219\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:220\n",
      "Length of sentence: 70, Number of samples:27\n",
      "\t\t 0  --  3.2078813e-16\n",
      "\t\t 1  --  4.25511e-14\n",
      "\t\t 2  --  1.0715322e-12\n",
      "\t\t 3  --  2.2794554e-11\n",
      "\t\t 4  --  2.7176472e-09\n",
      "\t\t 5  --  1.588329e-08\n",
      "\t\t 6  --  4.0756138e-08\n",
      "\t\t 7  --  5.889292e-06\n",
      "\t\t 8  --  4.07491e-05\n",
      "\t\t 9  --  4.07491e-05\n",
      "\t\t 10  --  4.07491e-05\n",
      "\t\t 11  --  0.00015954653\n",
      "\t\t 12  --  0.00015954653\n",
      "\t\t 13  --  0.00016419218\n",
      "\t\t 14  --  0.061033715\n",
      "\t\t 15  --  0.061033715\n",
      "\t\t 16  --  0.5125729\n",
      "Success and score: 0.5126\n",
      "magnificent ----> splendid\n",
      "form ----> format\n",
      "her ----> sa\n",
      "first ----> prima\n",
      "fine ----> fined\n",
      "support ----> aid\n",
      "rest ----> remaining\n",
      "which ----> whose\n",
      "includes ----> involves\n",
      "rugged ----> manly\n",
      "captures ----> captured\n",
      "gives ----> provide\n",
      "great ----> grand\n",
      "does ----> wo\n",
      "daughter ----> girl\n",
      "after ----> then\n",
      "years ----> aged\n",
      "also ----> besides\n",
      "great ----> grand\n",
      "great ----> grand\n",
      "----------------------\n",
      "Sequence number:221\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:222\n",
      "Wrong original prediction\n",
      "----------------------\n",
      "Sequence number:223\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:224\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:225\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:226\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:227\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:228\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:229\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:230\n",
      "Length of sentence: 35, Number of samples:28\n",
      "\t\t 0  --  1.0\n",
      "Success and score: 1.0000\n",
      "depressing ----> grim\n",
      "----------------------\n",
      "Sequence number:231\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:232\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:233\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:234\n",
      "Wrong original prediction\n",
      "----------------------\n",
      "Sequence number:235\n",
      "Wrong original prediction\n",
      "----------------------\n",
      "Sequence number:236\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:237\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:238\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:239\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:240\n",
      "Length of sentence: 99, Number of samples:29\n",
      "\t\t 0  --  1.6724337e-27\n",
      "\t\t 1  --  6.707895e-24\n",
      "\t\t 2  --  1.002467e-23\n",
      "\t\t 3  --  3.999231e-20\n",
      "\t\t 4  --  6.2573322e-18\n",
      "\t\t 5  --  1.582241e-17\n",
      "\t\t 6  --  1.582241e-17\n",
      "\t\t 7  --  1.5814038e-15\n",
      "\t\t 8  --  1.5814038e-15\n",
      "\t\t 9  --  3.5436213e-13\n",
      "\t\t 10  --  3.5436213e-13\n",
      "\t\t 11  --  9.068592e-11\n",
      "\t\t 12  --  9.068592e-11\n",
      "\t\t 13  --  9.068592e-11\n",
      "\t\t 14  --  4.0752213e-10\n",
      "\t\t 15  --  5.5985146e-07\n",
      "\t\t 16  --  5.5985146e-07\n",
      "\t\t 17  --  5.5985146e-07\n",
      "\t\t 18  --  5.5985146e-07\n",
      "\t\t 19  --  5.1422794e-06\n",
      "\t\t 20  --  5.1422794e-06\n",
      "\t\t 21  --  0.26456448\n",
      "\t\t 22  --  0.9948437\n",
      "Success and score: 0.9948\n",
      "probably ----> admittedly\n",
      "top ----> upper\n",
      "list ----> listed\n",
      "movies ----> cinema\n",
      "ever ----> permanently\n",
      "seen ----> noticed\n",
      "big ----> massive\n",
      "or ----> ni\n",
      "thieves ----> robbers\n",
      "different ----> differing\n",
      "made ----> introduced\n",
      "robin ----> rubin\n",
      "hilarious ----> fun\n",
      "extremely ----> hugely\n",
      "pleased ----> satisfied\n",
      "how ----> mode\n",
      "together ----> whole\n",
      "well ----> bah\n",
      "home ----> housing\n",
      "alone ----> merely\n",
      "move ----> shift\n",
      "ever ----> permanently\n",
      "especially ----> predominantly\n",
      "love ----> likes\n",
      "men ----> males\n",
      "if ----> unless\n",
      "good ----> decent\n",
      "----------------------\n",
      "Sequence number:241\n",
      "Length of sentence: 50, Number of samples:30\n",
      "\t\t 0  --  1.0\n",
      "Success and score: 1.0000\n",
      "hard ----> stiff\n",
      "----------------------\n",
      "Sequence number:242\n",
      "Wrong original prediction\n",
      "----------------------\n",
      "Sequence number:243\n",
      "Wrong original prediction\n",
      "----------------------\n",
      "Sequence number:244\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:245\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:246\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:247\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:248\n",
      "Length of sentence: 98, Number of samples:31\n",
      "\t\t 0  --  0.00014848268\n",
      "\t\t 1  --  0.0001617153\n",
      "\t\t 2  --  0.5264246\n",
      "Success and score: 0.5264\n",
      "greatest ----> larger\n",
      "dance ----> dancer\n",
      "sad ----> deplorable\n",
      "----------------------\n",
      "Sequence number:249\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:250\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:251\n",
      "Wrong original prediction\n",
      "----------------------\n",
      "Sequence number:252\n",
      "Wrong original prediction\n",
      "----------------------\n",
      "Sequence number:253\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:254\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:255\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:256\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:257\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:258\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:259\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:260\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:261\n",
      "Length of sentence: 63, Number of samples:32\n",
      "\t\t 0  --  1.0\n",
      "Success and score: 1.0000\n",
      "comedy ----> travesty\n",
      "----------------------\n",
      "Sequence number:262\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:263\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:264\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:265\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:266\n",
      "Length of sentence: 99, Number of samples:33\n",
      "\t\t 0  --  4.1714684e-23\n",
      "\t\t 1  --  3.4037106e-20\n",
      "\t\t 2  --  4.1582766e-18\n",
      "\t\t 3  --  6.9346335e-13\n",
      "\t\t 4  --  4.6697313e-11\n",
      "\t\t 5  --  5.7351343e-07\n",
      "\t\t 6  --  5.7351343e-07\n",
      "\t\t 7  --  5.7351343e-07\n",
      "\t\t 8  --  0.0012837884\n",
      "\t\t 9  --  0.0012837884\n",
      "\t\t 10  --  0.032667603\n",
      "\t\t 11  --  0.032667603\n",
      "\t\t 12  --  0.032667603\n",
      "\t\t 13  --  0.9842976\n",
      "Success and score: 0.9843\n",
      "award ----> prix\n",
      "reeks ----> scent\n",
      "sick ----> patient\n",
      "thankfully ----> happily\n",
      "watched ----> saw\n",
      "mike ----> geraldo\n",
      "bearable ----> livable\n",
      "horrid ----> horrific\n",
      "mother ----> momma\n",
      "silly ----> foolish\n",
      "premise ----> premises\n",
      "bad ----> wicked\n",
      "warned ----> wary\n",
      "suffer ----> undergoes\n",
      "defending ----> upholding\n",
      "----------------------\n",
      "Sequence number:267\n",
      "Wrong original prediction\n",
      "----------------------\n",
      "Sequence number:268\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:269\n",
      "Sequence is too long\n",
      "----------------------\n",
      "Sequence number:270\n",
      "Length of sentence: 90, Number of samples:34\n",
      "\t\t 0  --  2.5614471e-12\n",
      "\t\t 1  --  2.5219004e-11\n",
      "\t\t 2  --  1.889289e-10\n",
      "\t\t 3  --  2.3429092e-10\n",
      "\t\t 4  --  2.3429092e-10\n",
      "\t\t 5  --  6.174183e-09\n",
      "\t\t 6  --  6.174183e-09\n",
      "\t\t 7  --  1.6145611e-07\n",
      "\t\t 8  --  1.7652721e-06\n",
      "\t\t 9  --  1.7652721e-06\n",
      "\t\t 10  --  2.9366913e-06\n"
     ]
    }
   ],
   "source": [
    "TEST_SIZE = 200\n",
    "order_pre = 0\n",
    "n = 0\n",
    "seq_success = []\n",
    "seq_orig = []\n",
    "seq_orig_label = []\n",
    "word_varied = []\n",
    "test_loader = torch.load(os.path.join(save_path, 'test_loader'))\n",
    "if order_pre != 0:\n",
    "  seq_success = np.load(os.path.join(save_path,'seq_success.npy'))\n",
    "  seq_orig = np.load(os.path.join(save_path,'seq_orig.npy'))\n",
    "  seq_orig_label = np.load(os.path.join(save_path,'seq_orig_label.npy'))\n",
    "  word_varied = np.load(os.path.join(save_path,'word_varied.npy'))\n",
    "  n = len(seq_success)\n",
    "\n",
    "for order, (seq, l, target) in enumerate(test_loader):\n",
    "\n",
    "  if order>=order_pre:\n",
    "    print('Sequence number:{}'.format(order))\n",
    "    seq_len = np.sum(np.sign(seq.numpy()))\n",
    "    seq, l = seq.to(device), l.to(device)\n",
    "    seq = seq.type(torch.LongTensor)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      orig_pred = np.argmax(model.pred(seq, l).cpu().detach().numpy())\n",
    "    if orig_pred != target.numpy()[0]:\n",
    "      print('Wrong original prediction')\n",
    "      print('----------------------')\n",
    "      continue\n",
    "    if seq_len > 100:\n",
    "      print('Sequence is too long')\n",
    "      print('----------------------')\n",
    "      continue\n",
    "\n",
    "    print('Length of sentence: {}, Number of samples:{}'.format(l.item(), n+1))\n",
    "    seq_orig.append(seq[0].numpy())\n",
    "    seq_orig_label.append(target.numpy()[0])\n",
    "    target = 1-target.numpy()[0]\n",
    "    seq_success.append(ga_attack.attack(seq, target, l))\n",
    "    \n",
    "    if len(seq_success[n]) > 1:\n",
    "      w_be = [dataset.inv_dict[seq_orig[n][i]] for i in list(np.where(seq_success[n] != seq_orig[n])[0])]\n",
    "      w_to = [dataset.inv_dict[seq_success[n][i]] for i in list(np.where(seq_success[n] != seq_orig[n])[0])]\n",
    "      for i in range(len(w_be)):\n",
    "        print('{} ----> {}'.format(w_be[i], w_to[i]))\n",
    "      word_varied.append([w_be]+[w_to])\n",
    "    else:\n",
    "      print('Fail')\n",
    "    print('----------------------')\n",
    "    n += 1\n",
    "    \n",
    "    np.save(os.path.join(save_path,'seq_success.npy'), np.array(seq_success))\n",
    "    np.save(os.path.join(save_path,'seq_orig.npy'), np.array(seq_orig))\n",
    "    np.save(os.path.join(save_path,'seq_orig_label.npy'), np.array(seq_orig_label))\n",
    "    np.save(os.path.join(save_path,'word_varied.npy'), np.array(word_varied))\n",
    "    \n",
    "    if n>TEST_SIZE:\n",
    "      break "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "EPXS4zGXL-Xe"
   },
   "source": [
    "## Compute Attack success rate"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "f-E6IyzcL-W6",
    "cEdwMyz3L-XJ"
   ],
   "machine_shape": "hm",
   "name": "IMDB_Attack",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

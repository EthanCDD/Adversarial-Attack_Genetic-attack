# Adversarial attack and transferability
This is based on paper 'Generating Natural Language Adversarial Examples'. However, there are some changes:

The LSTM-based model is listed in the document of 'lstm_model' and bert-based model is listed in document of 'bert-model'.

In the document of 'lstm_model', it mainly includes the content of adversarial attack and defense; 'bert-model' includes the content of transferability.

The content of 'TextFooler' could be identified in the link of 'https://github.com/EthanCDD/TextFooler'

# Don't need to check the files of '.py' on this page since they are not organised well and they are included in the document of 'bert-model' and 'lstm-model'.
